# üóûÔ∏è News-Assistant  
**AI-Powered News Article Explainer**

- üîó Ingest articles from **URLs**
- üß© Intelligent document **chunking** and **embedding** using HuggingFace models
- üìö **FAISS**-based vector similarity search for relevant context retrieval
- ü§ñ Local **LLM interaction** using [Ollama](https://ollama.com/)
- üß† Supports **chat memory** and **follow-up questions**
- üí° Real-time explanations, summaries, and Q&A from long-form news articles
- üåê Fully **offline** and **privacy-friendly** ‚Äì No external API calls required

---

## üß™ Steps To Run

1. **Install Dependencies**

```bash
pip install -r requirements.txt
```

2. **Run a Local Model via Ollama**

```bash
ollama run llama3
```

> ‚ÑπÔ∏è To use a different model, update `model="llama3"` in `app.py`.

3. **Launch the Streamlit App**

```bash
streamlit run app.py
```

Open your browser at [http://localhost:8501](http://localhost:8501)

---
